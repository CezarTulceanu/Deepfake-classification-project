# -*- coding: utf-8 -*-
"""Kaggle,pynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Om9DbQF4Oz73OFymT1yGEiZvxPLwTDyb
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install -q kaggle

from google.colab import files
files.upload() 

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json


#Descarcam datele
!kaggle competitions download -c deepfake-classification-unibuc

!unzip -q deepfake-classification-unibuc.zip -d deepfake_data

import os

for root, dirs, files in os.walk("deepfake_data"):
    print(root, len(files), "files")

from PIL import Image
import matplotlib.pyplot as plt
import os

train_dir = "deepfake_data/train"

img_files = sorted([
    f for f in os.listdir(train_dir)
    if f.lower().endswith(('.jpg', '.jpeg', '.png'))
])

first_img_path = os.path.join(train_dir, img_files[0])
img = Image.open(first_img_path)


#Aici am afisat prima imagine pentru a-mi face o idee ce contine 
plt.imshow(img)
plt.title(f"First train image: {img_files[0]}")
plt.axis('off')
plt.show()

import os
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
import matplotlib as plt

BASE_DIR = "deepfake_data"
TRAIN_IMG_DIR = os.path.join(BASE_DIR, "train")
TEST_IMG_DIR = os.path.join(BASE_DIR, "test")
VALIDATION_IMG_DIR = os.path.join(BASE_DIR, "validation")
TRAIN_CSV_PATH = os.path.join(BASE_DIR, "train.csv")
VALIDATION_CSV_PATH = os.path.join(BASE_DIR, "validation.csv")

IMG_SIZE = (128, 128)
BATCH_SIZE = 32
EPOCHS = 10

train_df = pd.read_csv(TRAIN_CSV_PATH)
train_df["image_id"] = train_df["image_id"].astype(str) + ".png" 
train_df["label"] = train_df["label"].astype(str)

val_df = pd.read_csv(VALIDATION_CSV_PATH)
val_df["image_id"] = val_df["image_id"].astype(str) + ".png"
val_df["label"] = val_df["label"].astype(str)


#Aici scalam valorile imaginilor ca sa le ducem in intervalul [0,1] ca sa fie mai usor sa lucram cu ele

#Nu facem nicio augmentare

train_gen = ImageDataGenerator(rescale=1./255)
val_gen = ImageDataGenerator(rescale=1./255)

train_data = train_gen.flow_from_dataframe(
    train_df,
    directory=TRAIN_IMG_DIR,
    x_col="image_id",
    y_col="label",
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

val_data = val_gen.flow_from_dataframe(
    val_df,
    directory=VALIDATION_IMG_DIR,
    x_col="image_id",
    y_col="label",
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    shuffle=False
)

#Un model convolutional simplu, de inceput

model = models.Sequential([
    layers.Input(shape=(*IMG_SIZE, 3)),
    layers.Conv2D(32, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dense(5, activation='softmax')
])

#Folosim lucruri standard

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

#Antrenam modelul

history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=EPOCHS
)

#Salvam graficele

plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title("Accuracy per Epoch")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.grid()
plt.savefig("accuracy_plot.png")

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title("Loss per Epoch")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.grid()
plt.savefig("loss_plot.png")
plt.close()

# Confusion matrix
val_preds = model.predict(val_data)
val_preds_labels = np.argmax(val_preds, axis=1)
true_labels = val_data.classes

cm = confusion_matrix(true_labels, val_preds_labels)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.savefig("confusion_matrix.png")
plt.close()

test_filenames = sorted([f for f in os.listdir(TEST_IMG_DIR) if f.endswith(".png")])
test_df = pd.DataFrame({"filename": test_filenames})

test_data = test_gen.flow_from_dataframe(
    test_df,
    directory=TEST_IMG_DIR,
    x_col="filename",
    class_mode=None,
    target_size=IMG_SIZE,
    batch_size=1,
    shuffle=False
)

preds = model.predict(test_data, verbose=1)
predicted_labels = preds.argmax(axis=1)

submission = pd.DataFrame({
    "image": test_df["filename"],
    "label": predicted_labels
})

submission.to_csv("submission.csv", index=False)
submission.head()

submission = pd.DataFrame({
    "image_id": test_df["filename"].str.replace(".png", "", regex=False),
    "label": predicted_labels
})

submission.to_csv("submission.csv", index=False)
submission.head()
